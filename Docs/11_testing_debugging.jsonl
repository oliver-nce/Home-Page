{"chunk_id": "11_testing_debugging__testing__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/testing", "title": "Testing", "section_heading": "Writing Tests", "content": "## Writing Tests\n\nFrappe provides some basic tooling to write automated tests. There are some\nbasic rules:\n\n1. Test can be anywhere in your repository but must begin with `test_` and\n   should be a `.py` file.\n2. The test runner will automatically build test records for dependent DocTypes\n   identified by the `Link` type field (Foreign Key).\n3. For non-DocType tests, you can write simple unit tests and prefix your file\n   names with `test_`.\n\n### Writing Tests\n\nWhen you create a new DocType (in developer mode), the boilerplate files also\ncontain the `test_{doctype}.py` file. The test file should handle creating\ndependencies and cleaning them up.\n\nHere is a sample test file referred from `test_event.py`.\n\n```python\nimport frappe\nimport unittest\n\ndef create_events():\n if frappe.flags.test_events_created:\n return\n\n frappe.set_user(\"Administrator\")\n doc = frappe.get_doc({\n \"doctype\": \"Event\",\n \"subject\":\"_Test Event 1\",\n \"starts_on\": \"2014-01-01\",\n \"event_type\": \"Public\"\n }).insert()\n\n doc = frappe.get_doc({\n \"doctype\": \"Event\",\n \"subject\":\"_Test Event 3\",\n \"starts_on\": \"2014-01-01\",\n \"event_type\": \"Public\"\n \"event_individuals\": [{\n \"person\": \"test1@example.com\"\n }]\n }).insert()\n\n frappe.flags.test_events_created = True\n\nclass TestEvent(unittest.TestCase):\n def setUp(self):\n create_events()\n\n def tearDown(self):\n frappe.set_user(\"Administrator\")\n\n def test_allowed_public(self):\n frappe.set_user(\"test1@example.com\")\n doc = frappe.get_doc(\"Event\", frappe.db.get_value(\"Event\",\n {\"subject\":\"_Test Event 1\"}))\n self.assertTrue(frappe.has_permission(\"Event\", doc=doc))\n\n def test_not_allowed_private(self):\n frappe.set_user(\"test1@example.com\")\n doc = frappe.get_doc(\"Event\", frappe.db.get_value(\"Event\",\n {\"subject\":\"_Test Event 2\"}))\n self.assertFalse(frappe.has_permission(\"Event\", doc=doc))\n```", "content_type": "mixed", "has_code": true, "token_count": 453}
{"chunk_id": "11_testing_debugging__testing__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/testing", "title": "Testing", "section_heading": "Writing Tests for Commands", "content": "## Writing Tests for Commands\n\nTo write tests for your Bench commands, you can group your tests under a\nClass that extends `BaseTestCommands` from `frappe.tests.test_commands` and\n`unittest.TestCase` so that it runs during the `bench run-tests` command.\n\nFor reference, here is are some tests written for the `bench execute` command.\n\n```python\nclass TestCommands(BaseTestCommands, unittest.TestCase):\n def test_execute(self):\n # test 1: execute a command expecting a numeric output\n self.execute(\"bench --site {site} execute frappe.db.get_database_size\")\n self.assertEqual(self.returncode, 0)\n self.assertIsInstance(float(self.stdout), float)\n\n # test 2: execute a command expecting an errored output as local won't exist\n self.execute(\"bench --site {site} execute frappe.local.site\")\n self.assertEqual(self.returncode, 1)\n self.assertIsNotNone(self.stderr)\n\n # test 3: execute a command with kwargs\n # Note:\n # terminal command has been escaped to avoid .format string replacement\n # The returned value has quotes which have been trimmed for the test\n self.execute(\"\"\"bench --site {site} execute frappe.bold --kwargs ''\"\"\")\n self.assertEqual(self.returncode, 0)\n self.assertEqual(self.stdout[1:-1], frappe.bold(text='DocType'))\n```", "content_type": "mixed", "has_code": true, "token_count": 308}
{"chunk_id": "11_testing_debugging__testing__003", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/testing", "title": "Testing", "section_heading": "Running Tests", "content": "## Running Tests\n\nRunning tests could require additional dependencies specified by apps in their `dev-requirements.txt` file. Before running tests, make sure all apps have development dependencies installed using `bench setup requirements --dev`.\n\nRun the following command to run all your tests. It will build all\nthe test dependencies once and run your tests. You should run tests from\n`frappe_bench` folder.\n\n```python\n# run all tests\nbench --site [sitename] run-tests\n\n# run tests for only frappe app\nbench --site [sitename] run-tests --app frappe\n\n# run tests for the Task doctype\nbench --site [sitename] run-tests --doctype \"Task\"\n\n# run tests for All doctypes in specified Module Def\nbench --site [sitename] run-tests --module-def \"Contacts\"\n\n# run a test using module path\nbench --site [sitename] run-tests --module frappe.tests.test_api\n\n# run a specific test from a test file\nbench --site [sitename] run-tests --module frappe.tests.test_api --test test_insert_many\n\n# run tests without creating test records\nbench --site [sitename] run-tests --skip-test-records --doctype \"Task\"\n\n# profile tests and show a report after tests execute\nbench --site [sitename] run-tests --profile --doctype \"Task\"\n.\n----------------------------------------------------------------------\nRan 1 test in 0.010s\n\nOK\n\n9133 function calls (8912 primitive calls) in 0.011 seconds\n\nOrdered by: cumulative time\n\nncalls tottime percall cumtime percall filename:lineno(function)\n 2 0.000 0.000 0.008 0.004 /home/frappe/frappe-bench/apps/frappe/frappe/model/document.py:187(insert)\n 1 0.000 0.000 0.003 0.003 /home/frappe/frappe-bench/apps/frappe/frappe/model/document.py:386(_validate)\n 13 0.000 0.000 0.002 0.000 /home/frappe/frappe-bench/apps/frappe/frappe/database.py:77(sql)\n 255 0.000 0.000 0.002 0.000 /home/frappe/frappe-bench/apps/frappe/frappe/model/base_document.py:91(get)\n 12 0.000 0.000 0.002 0.000\n\n# verbose log level for tests\nbench --site [sitename] --verbose run-tests\n```\n\n### Running Tests Parallelly\n\nAs the number of tests grows in the project, it takes a long time for tests to complete if it runs serially on one machine.\nRunning tests in parallel across many test machines can save time in Continuous Integration (CI).", "content_type": "mixed", "has_code": true, "token_count": 555}
{"chunk_id": "11_testing_debugging__testing__004", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/testing", "title": "Testing", "section_heading": "Parallel Tests", "content": "## Parallel Tests\n\n**Command:**\n\n```python\nbench --site [sitename] --app [app-name] run-parallel-tests --build-id <build-number> --total-build <total-number-of-builds>\n```\n\n**Usage:**\n\nIf you want to run tests across 2 CI instances your command will be as follows:\n\n```python\n# in first CI instance\nbench --site [sitename] run-parallel-tests --build-id 1 --total-builds 2\n\n# in second CI instance\nbench --site [sitename] run-parallel-tests --build-id 2 --total-builds 2\n```\n\n**Note:** The command will split all test files into 2 parts and execute them in those CI instances.\nThe first half of the test list will be executed in the first instance and the second half of the test list will be executed in the second instance.\n\n### Parallel tests with orchestrator\n\nIt may happen that each test takes a different amount of time for completion which may result in imbalanced time across CI builds. To mitigate this you can use [test orchestrator](https://github.com/frappe/test-orchestrator) which runs the next test based on the availability of CI instance. The command to use the test orchestrator for the parallel test is as follows.\n\n**Command:**\n\n```python\nbench --site [sitename] --app [app-name] run-parallel-tests --use-orchestrator\n```\n\n**Usage:**\n\nIf you want to run tests across 2 CI instances your command will be as follows\n\n```python\n# in first CI instance\nbench --site [sitename] run-parallel-tests --use-orchestrator\n\n# in second CI instance\nbench --site [sitename] run-parallel-tests --use-orchestrator\n```\n\n**Note:** Environment variables `CI_BUILD_ID` and `ORCHESTRATOR_URL` are required for this command. `CI_BUILD_ID` is the unique ID that you get for each build run of CI.\n`ORCHESTRATOR_URL` is the publicly accessible URL that you get after hosting the [orchestrator](https://github.com/frappe/test-orchestrator).", "content_type": "mixed", "has_code": true, "token_count": 458}
{"chunk_id": "11_testing_debugging__testing__005", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/testing", "title": "Testing", "section_heading": "Comparison", "content": "## Comparison\n\nFor clarity on how the above variants of parallel test commands may work check the following example.\n\nSuppose there are 4 test files as follows\n\n```python\ntest_module_one.py 4 mins (execution time)\ntest_module_two.py 2 mins\ntest_module_three.py 1 min\ntest_module_four.py 1 min\n```\n\nTime required without parallel test command.\n\n```python\ntest_module_one.py 4 mins\ntest_module_two.py 2 mins\ntest_module_three.py 1 min\ntest_module_four.py 1 min\n==============================\nTotal Wait Time 8 mins\n```\n\nTime required with the first command that auto splits test files across 2 test instances.\n\n```python\n# First instance # Second instance\ntest_module_one.py 4 mins test_module_three.py 1 min\ntest_module_two.py 2 mins test_module_four.py 1 min\n---------------------------- ----------------------------\n 6 mins 2 mins\n\n==============================\nTotal Wait Time 6 mins\n```\n\nIt may happen that the time required with the second command that uses orchestrator which runs tests based on availability across 2 test instances.\n\n```python\n# First instance # Second instance\ntest_module_one.py 4 mins test_module_two.py 2 mins\n---------------------------- test_module_three.py 1 mins\n 4 mins test_module_four.py 1 min\n ----------------------------\n 4 mins\n==============================\nTotal Wait Time 4 mins\n```\n\n**Note:** Only one test file is executed on the first instance because it is busy for 4 mins. By that time, the 2nd instance is able to execute other test files which help in balancing time across builds.", "content_type": "mixed", "has_code": true, "token_count": 382}
{"chunk_id": "11_testing_debugging__ui-testing__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/ui-testing", "title": "Ui Testing", "section_heading": "Example", "content": "## Example\n\nYou can write UI tests using [Cypress](https://cypress.io). It is a NodeJS based\nfull-stack testing framework which doesn't rely on Selenium.\n\nTo write integration tests, create a `.js` file in the `cypress/integration`\ndirectory.\n\n### Example\n\nHere is an example of an integration test to check insertion of a ToDo\n\n```python\ncontext('ToDo', () => {\n before(() => {\n cy.login('Administrator', 'admin');\n cy.visit('/desk');\n });\n\n it('creates a new todo', () => {\n cy.visit('/app/todo/new-todo-1');\n cy.fill_field('description', 'this is a test todo', 'Text Editor').blur();\n cy.get('.page-title').should('contain', 'Not Saved');\n cy.get('.primary-action').click();\n cy.visit('/desk#List/ToDo');\n cy.location('hash').should('eq', '/app/todo');\n cy.get('.list-row').should('contain', 'this is a test todo');\n });\n});\n```", "content_type": "mixed", "has_code": true, "token_count": 207}
{"chunk_id": "11_testing_debugging__ui-testing__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/ui-testing", "title": "Ui Testing", "section_heading": "Running Cypress Locally", "content": "## Running Cypress Locally\n\nCypress uses any chromium based browser installed on your system to run tests.\nEvery app has it's own cypress test suite. To run test for an app, run the\nfollowing command from the `frappe-bench` directory.\n\n```python\nbench --site [sitename] run-ui-tests [app]\n```\n\nThis will open the Cypress Electron shell where you can run any test manually or\nrun all of the tests.\n\nYou can also run tests in headless mode.\n\n```python\n# run in headless mode\nbench --site [sitename] run-ui-tests [app] --headless\n```\n\nTo enable cypress parallel testing you can pass `--parallel` flag.\nMore information on how cypress parallel tests work can be found [here](https://docs.cypress.io/guides/guides/parallelization).\n\n```python\n# run tests parallelly\nbench --site [sitename] run-ui-tests [app] --parallel\n```\n\n### Code Coverage\n\nCode coverage helps to identify which lines of the source code were executed during the tests. In order to measure code coverage, the source code needs to be instrumented and this instrumented source code needs to be integrated with our test runner to collect the coverage and generate a report.\n\nFor Cypress tests in Frappe, the `.js` files are instrumented using [Istanbul](https://istanbul.js.org/) and the [Cypress code-coverage plugin](https://github.com/cypress-io/code-coverage) is used to merge coverage from each test and save the combined result.\n\n**Code Instrumentation:**\n\nIn order to compute which lines of the source code were executed, additional counters are inserted into the code through **\\_instrumentation\\_**. For example:\n\nBefore instrumentation:\n\n```python\nfunction foo(a, b) {\n if (a < b)\n return b - a;\n else\n return a - b;\n}\n```\n\nAfter instrumentation:\n\n```python\ncov_1m1jljnmzu();\n\nfunction foo(a, b) {\n cov_1m1jljnmzu().f[0]++;\n cov_1m1jljnmzu().s[0]++;\n\n if (a < b) {\n cov_1m1jljnmzu().b[0][0]++;\n cov_1m1jljnmzu().s[1]++;\n return b - a;\n } else {\n cov_1m1jljnmzu().b[0][1]++;\n cov_1m1jljnmzu().s[2]++;\n return a - b;\n }\n}\n```\n\nWhen using this modified (instrumented) source code for testing, these counters get incremented as the code is executed, and a coverage object is generated. The Cypress code-coverage plugin then handles the collected coverage and generates coverage reports.\n\n**Generating Code Coverage Report Locally:**\n\n1. Instrument source code using [istanbul/nyc](https://github.com/istanbuljs/nyc) :\n\n```python\nnpx nyc instrument -x 'frappe/public/dist/**' -x 'frappe/public/js/lib/**' -x '**/*.bundle.js' --compact=false --in-place frappe\n```\n\nThis replaces the existing source code in the frappe folder with the instrumented source code. The `-x` flag is used to exclude specified paths. You can also use the `-n` flag to specify paths to be included. See [here](https://github.com/istanbuljs/nyc/blob/master/docs/instrument.md) for more details about the `nyc instrument` command\n\n2. Run Cypress tests:\n\n```python\nbench --site test_site run-ui-tests frappe --with-coverage\n```\n\n3. Generate report:\n\n```python\nnpx nyc report --reporter=text\n```\n\nSee [here](https://istanbul.js.org/docs/advanced/alternative-reporters/) for alternate report formats", "content_type": "mixed", "has_code": true, "token_count": 783}
{"chunk_id": "11_testing_debugging__ui-testing__003", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/ui-testing", "title": "Ui Testing", "section_heading": "Testing-Library Queries", "content": "## Testing-Library Queries\n\nYou can also use [Testing Library](https://testing-library.com/) queries within your Cypress tests. Testing Library provides testing utilities that:\n\n* Make it easier to write UI tests that resemble the way users interact with the app\n* Make it easier to find elements in the DOM without knowing all the implementation details\n* Help keep the tests maintainable (so minor refactors don't break tests)\n\n> See [Testing Library Docs](https://testing-library.com/docs/queries/about) for more details about usage\n\nTesting Library provides several queries to find elements on a page. Here are some examples:\n\n* [ByRole](https://testing-library.com/docs/queries/byrole)\n\nLook [here](https://www.w3.org/TR/html-aria/#docconformance) for table of HTML elements and their default roles\n\n| Query | Element |\n| --- | --- |\n| `findByRole('button', {name: 'Save'})` | `` with [accessible name](https://www.tpgi.com/what-is-an-accessible-name/) = 'Save' |\n| `findByRole('checkbox')` | `` |\n| `findByRole('textbox')` | `,`  \\_(Also matches other elements with default role='textbox')\\_ |\n| `findByRole('searchbox')` | `<input type=search>` |\n| `findByRole('listbox')` | `<select>`, `<datalist>` |\n\n* [ByLabelText](https://testing-library.com/docs/queries/bylabeltext)\n\n| Query | Element |\n| --- | --- |\n| `findByLabelText('Optimize')` | element associated with the label 'Optimize' |\n\n* [ByPlaceholderText](https://testing-library.com/docs/queries/byplaceholdertext)\n\n| Query | Element |\n| --- | --- |\n| `findByPlaceholderText('Name')` | element with placeholder='Name' |\n\n* [ByText](https://testing-library.com/docs/queries/bytext)\n\n| Query | Element |\n| --- | --- |\n| `findByText('example.json')` | element with textContent='example.json' |\n\n* [ByDisplayValue](https://testing-library.com/docs/queries/bydisplayvalue)\n\n| Query | Element |\n| --- | --- |\n| `findByDisplayValue('Option 1')` | `<select>` with selected `<option>` 'Option 1' \\_(Also matches `<input>` or `<textarea>` with matching value attribute)\\_ |\n\n* [ByTitle](https://testing-library.com/docs/queries/bytitle)\n\n| Query | Element |\n| --- | --- |\n| `findByTitle('Open Link')` | element with title='Open Link' |\n\n* [ByAltText](https://testing-library.com/docs/queries/byalttext/)\n* [ByTestId](https://testing-library.com/docs/queries/bytestid/)", "content_type": "prose", "has_code": false, "token_count": 580}
{"chunk_id": "11_testing_debugging__guides__automated-testing__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing", "title": "Automated Testing", "section_heading": "", "content": "Frappe Provides you a test framework to write and execute tests that can be run directly on a Continuous Integration Tool like Travis\n\nYou can write server-side unit tests or UI tests", "content_type": "prose", "has_code": false, "token_count": 45}
{"chunk_id": "11_testing_debugging__guides__automated-testing__unit-testing__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/unit-testing", "title": "Unit Testing", "section_heading": "1.Introduction", "content": "## 1.Introduction\n\nFrappe provides some basic tooling to quickly write automated tests. There are some basic rules:\n\n1. Test can be anywhere in your repository but must begin with `test_` and should be a `.py` file.\n2. Tests must run on a site that starts with `test_`. This is to prevent accidental loss of data.\n3. Test stubs are automatically generated for new DocTypes.\n4. Frappe test runner will automatically build test records for dependant DocTypes identified by the `Link` type field (Foreign Key)\n5. Tests can be executed using `bench run-tests`\n6. For non-DocType tests, you can write simple unittests and prefix your file names with `test_`.\n\n### 2.1. Writing DocType Tests:\n\n1. Test cases are in a file named `test_[doctype].py`\n2. You must create all dependencies in the test file\n3. Create a Python module structure to create fixtures / dependencies", "content_type": "prose", "has_code": false, "token_count": 216}
{"chunk_id": "11_testing_debugging__guides__automated-testing__unit-testing__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/unit-testing", "title": "Unit Testing", "section_heading": "MIT License. See license.txt", "content": "## MIT License. See license.txt\n\nimport frappe\nimport frappe.defaults\n\nfrom frappe.tests.utils import FrappeTestCase\n\ndef create\\_events():\nif frappe.flags.test\\_events\\_created:\nreturn\n\nfrappe.set\\_user(\"Administrator\")\ndoc = frappe.get\\_doc({\n\"doctype\": \"Event\",\n\"subject\":\"\\_Test Event 1\",\n\"starts\\_on\": \"2014-01-01\",\n\"event\\_type\": \"Public\"\n}).insert()\n\ndoc = frappe.get\\_doc({\n\"doctype\": \"Event\",\n\"subject\":\"\\_Test Event 2\",\n\"starts\\_on\": \"2014-01-01\",\n\"event\\_type\": \"Private\"\n}).insert()\n\ndoc = frappe.get\\_doc({\n\"doctype\": \"Event\",\n\"subject\":\"\\_Test Event 3\",\n\"starts\\_on\": \"2014-01-01\",\n\"event\\_type\": \"Public\"\n\"event\\_individuals\": [{\n\"person\": \"test1@example.com\"\n}]\n}).insert()\n\nfrappe.flags.test\\_events\\_created = True\n\nclass TestEvent(FrappeTestCase):\ndef setUp(self):\ncreate\\_events()\n\ndef tearDown(self):\nfrappe.set\\_user(\"Administrator\")\n\ndef test\\_allowed\\_public(self):\nfrappe.set\\_user(\"test1@example.com\")\ndoc = frappe.get\\_doc(\"Event\", frappe.db.get\\_value(\"Event\",\n{\"subject\":\"\\_Test Event 1\"}))\nself.assertTrue(frappe.has\\_permission(\"Event\", doc=doc))\n\ndef test\\_not\\_allowed\\_private(self):\nfrappe.set\\_user(\"test1@example.com\")\ndoc = frappe.get\\_doc(\"Event\", frappe.db.get\\_value(\"Event\",\n{\"subject\":\"\\_Test Event 2\"}))\nself.assertFalse(frappe.has\\_permission(\"Event\", doc=doc))\n\ndef test\\_allowed\\_private\\_if\\_in\\_event\\_user(self):\ndoc = frappe.get\\_doc(\"Event\", frappe.db.get\\_value(\"Event\",\n{\"subject\":\"\\_Test Event 3\"}))\n\nfrappe.set\\_user(\"test1@example.com\")\nself.assertTrue(frappe.has\\_permission(\"Event\", doc=doc))\n\ndef test\\_event\\_list(self):\nfrappe.set\\_user(\"test1@example.com\")\nres = frappe.get\\_list(\"Event\", filters=[[\"Event\", \"subject\", \"like\", \"\\_Test Event%\"]], fields=[\"name\", \"subject\"])\nself.assertEqual(len(res), 2)\nsubjects = [r.subject for r in res]\nself.assertTrue(\"\\_Test Event 1\" in subjects)\nself.assertTrue(\"\\_Test Event 3\" in subjects)\nself.assertFalse(\"\\_Test Event 2\" in subjects)\n\n### 2. Running Tests\n\nThis function will build all the test dependencies and run your tests.\nYou should run tests from \"frappe\\_bench\" folder. Without options all tests will be run.\n\nbench run-tests\n\nIf you need more information about test execution - you can use verbose log level for bench.\n\nbench --verbose run-tests\n\n### Options:\n\n--app \n--doctype \n--test \n--module  (Run a particular module that has tests)\n--profile (Runs a Python profiler on the test)\n--junit-xml-output (The command provides test results in the standard XUnit XML format)\n\n### 2.1. Example for app:\n\nAll applications are located in folder: \"~/frappe-bench/apps\".\nWe can run tests for each application.\n\n* frappe-bench/apps/erpnext/\n* frappe-bench/apps/erpnext\\_demo/\n* frappe-bench/apps/frappe/\n\nbench run-tests --app erpnext\nbench run-tests --app erpnext\\_demo\nbench run-tests --app frappe\n\n### frappe@erpnext:~/frappe-bench$ bench run-tests --doctype \"Activity Cost\" .\n\nRan 1 test in 0.008s\n\nOK\n\n### 2.3. Example for test:\n\nRun a specific case in User:\n\n### frappe@erpnext:~/frappe-bench$ bench run-tests --doctype User --test test\\_get\\_value .\n\nRan 1 test in 0.005s\n\nOK\n\n### 2.4. Example for module:\n\nIf we want to run tests in the module:\n\n/home/frappe/frappe-bench/apps/erpnext/erpnext/support/doctype/issue/test\\_issue.py\n\nWe should use module name like this (related to application folder)\n\nerpnext.support.doctype.issue.test\\_issue\n\n### frappe@erpnext:~/frappe-bench$ bench run-tests --module \"erpnext.stock.doctype.stock\\_entry.test\\_stock\\_entry\" ...........................\n\nRan 27 tests in 30.549s", "content_type": "prose", "has_code": false, "token_count": 882}
{"chunk_id": "11_testing_debugging__guides__automated-testing__unit-testing__003", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/unit-testing", "title": "Unit Testing", "section_heading": "frappe@erpnext:~/frappe-bench$ bench run-tests --doctype \"Activity Cost\" --profile .", "content": "## frappe@erpnext:~/frappe-bench$ bench run-tests --doctype \"Activity Cost\" --profile .\n\nRan 1 test in 0.010s\n\nOK\n9133 function calls (8912 primitive calls) in 0.011 seconds\n\nOrdered by: cumulative time\n\nncalls tottime percall cumtime percall filename:lineno(function)\n2 0.000 0.000 0.008 0.004 /home/frappe/frappe-bench/apps/frappe/frappe/model/document.py:187(insert)\n1 0.000 0.000 0.003 0.003 /home/frappe/frappe-bench/apps/frappe/frappe/model/document.py:386(\\_validate)\n13 0.000 0.000 0.002 0.000 /home/frappe/frappe-bench/apps/frappe/frappe/database.py:77(sql)\n255 0.000 0.000 0.002 0.000 /home/frappe/frappe-bench/apps/frappe/frappe/model/base\\_document.py:91(get)\n12 0.000 0.000 0.002 0.000\n\n### 2.6 Running Tests without creating fixtures or before\\_tests hook\n\n* When you are building a feature it is useful to write tests without building test dependencies (i.e build fixtures for linked objects), with `--skip-test-records`\n* You can also skip the test initialisation script with `--skip-before-tests`\n\nExample\n\nbench --site school.erpnext.local run-tests --doctype \"Student Group\" --skip-test-records --skip-before-tests", "content_type": "prose", "has_code": false, "token_count": 283}
{"chunk_id": "11_testing_debugging__guides__automated-testing__unit-testing__004", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/unit-testing", "title": "Unit Testing", "section_heading": "3.0 `FrappeTestCase`", "content": "## 3.0 `FrappeTestCase`\n\n`FrappeTestCase` is Frappe Framework specific TestCase class extended from `unittest.TestCase`. Inherting this class in your tests ensures:\n\n1. `frappe.local.flags` and other most used local proxies are reset after test case runs.\n2. database - a new [database transaction](https://frappeframework.com/docs/v14/user/en/api/database#database-transaction-model) is started before testcase begins and rolled back after tests are finished.\n\nUsage\n\n```python\n# app/doctype/dt/test_dt.py\n\nfrom frappe.tests.utils import FrappeTestCase\n\nclass TestDt(FrappeTestCase):\n @classmethod\n def setUpClass(cls):\n super().setUpClass() # important to call super() methods when extending TestCase. \n ...\n```\n\n### How to run:\n\nbench run-tests --junit-xml-output=/reports/junit\\_test.xml\n\n### Example of test report:\n\ndetails about failure \n\nIt\u2019s designed for the CI Jenkins, but will work for anything else that understands an XUnit-formatted XML representation of test results.\n\n### Jenkins configuration support:\n\n1. You should install xUnit plugin - https://wiki.jenkins-ci.org/display/JENKINS/xUnit+Plugin\n2. After installation open Jenkins job configuration, click the box named \u201cPublish JUnit test result report\u201d under the \"Post-build Actions\" and enter path to XML report:\n   (Example: \\_reports/\\*.xml\\_)", "content_type": "mixed", "has_code": true, "token_count": 329}
{"chunk_id": "11_testing_debugging__guides__automated-testing__integration-testing__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/integration-testing", "title": "Integration Testing", "section_heading": "Example", "content": "## Example\n\nYou can write integration tests using [Cypress](https://cypress.io). It is a NodeJS based full-stack testing framework which doesn't rely on Selenium.\n\nTo write integration tests, create a `.js` file in the `cypress/integration` directory.\n\n### Example\n\nHere is an example of an integration test to check insertion of a To Do\n\n```python\ncontext('ToDo', () => {\n before(() => {\n cy.login('Administrator', 'admin');\n cy.visit('/desk');\n });\n\n it('creates a new todo', () => {\n cy.visit('/app/todo/new-todo-1');\n cy.fill_field('description', 'this is a test todo', 'Text Editor').blur();\n cy.get('.page-title').should('contain', 'Not Saved');\n cy.get('.primary-action').click();\n cy.visit('/desk#List/ToDo');\n cy.location('hash').should('eq', '/app/todo');\n cy.get('.list-row').should('contain', 'this is a test todo');\n });\n});\n```", "content_type": "mixed", "has_code": true, "token_count": 210}
{"chunk_id": "11_testing_debugging__guides__automated-testing__integration-testing__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/integration-testing", "title": "Integration Testing", "section_heading": "Running Cypress Locally", "content": "## Running Cypress Locally\n\nCypress uses any chromium based browser installed on your system to run tests. Every app has it's own cypress test suite.\nFor example, to run test for the `frappe` app, run the following commands\n\n```python\ncd ~/frappe-bench/apps/frappe\nyarn cypress:open\n```\n\nThis will open the Cypress Electron shell where you can run any test manually or run all of the tests.\n\n![](/files/running-cypress-tests.gif)", "content_type": "mixed", "has_code": true, "token_count": 107}
{"chunk_id": "11_testing_debugging__guides__automated-testing__qunit-testing__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/qunit-testing", "title": "Qunit Testing", "section_heading": "Test Runner", "content": "## Test Runner\n\nYou can either write integration tests, or directly write tests in Javascript using [QUnit](http://api.qunitjs.com/)\n\nQUnit helps you write UI tests using the QUnit framework and native frappe API. As you might have guessed, this is a much faster way of writing tests.\n\n### Test Runner\n\nTo write QUnit based tests, add your tests in the `tests/ui` folder of your application. Your test files must begin with `test_` and end with `.js` extension.\n\nTo run your files, you can use the **Test Runner**. The **Test Runner** gives a user interface to load all your QUnit tests and run them in the browser.\n\nIn the CI, all QUnit tests are run by the **Test Runner** using `frappe/tests/test_test_runner.py`\n\n![](/files/test-runner.png)\n\n### Running Tests\n\nTo run a Test Runner based test, use the `run-ui-tests` bench command by passing the name of the file you want to run.\n\nbench run-ui-tests --test frappe/tests/ui/test\\_list.js\n\nThis will pass the filename to `test_test_runner.py` that will load the required JS in the browser and execute the tests\n\n### Debugging Tests\n\nTo debug a test, you can open it in the **Test Runner** from your UI and run it manually to see where it is exactly failing.\n\n### Test Sequence\n\nIn Frappe UI tests are run in a fixed sequence to ensure dependencies.\n\nThe sequence in which the tests will be run will be in `tests/ui/tests.txt`\nfile.\n\n### Running All UI Tests\n\nTo run all UI tests together for your app run\n\nbench run-ui-tests --app [app\\_name]\n\nThis will run all the files in your `tests/ui` folder one by one.", "content_type": "prose", "has_code": false, "token_count": 390}
{"chunk_id": "11_testing_debugging__guides__automated-testing__qunit-testing__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/guides/automated-testing/qunit-testing", "title": "Qunit Testing", "section_heading": "Example QUnit Test", "content": "## Example QUnit Test\n\nHere is the example of the To Do test in QUnit\n\nQUnit.test(\"Test quick entry\", function(assert) {\nassert.expect(2);\nlet done = assert.async();\nlet random\\_text = frappe.utils.get\\_random(10);\n\nfrappe.run\\_serially([\n() => frappe.set\\_route('List', 'ToDo'),\n() => frappe.new\\_doc('ToDo'),\n() => frappe.quick\\_entry.dialog.set\\_value('description', random\\_text),\n() => frappe.quick\\_entry.insert(),\n(doc) => {\nassert.ok(doc && !doc.\\_\\_islocal);\nreturn frappe.set\\_route('Form', 'ToDo', doc.name);\n},\n() => assert.ok(cur\\_frm.doc.description.includes(random\\_text)),\n\n// Delete the created ToDo\n() => frappe.tests.click\\_page\\_head\\_item('Menu'),\n() => frappe.tests.click\\_dropdown\\_item('Delete'),\n() => frappe.tests.click\\_page\\_head\\_item('Yes'),\n\n() => done()\n]);\n});\n\n### Writing Test Friendly Code with Promises\n\nPromises are a great way to write test-friendly code. If your method calls an aysnchronous call (ajax), then you should return an `Promise` object. While writing tests, if you encounter a function that does not return a `Promise` object, you should update the code to return a `Promise` object.", "content_type": "prose", "has_code": false, "token_count": 283}
{"chunk_id": "11_testing_debugging__debugging__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "", "content": "</erpnext.projects.doctype.task.task.task>", "content_type": "prose", "has_code": false, "token_count": 10}
{"chunk_id": "11_testing_debugging__debugging__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "Server", "content": "## Server\n\nWhen you run the `bench start` command during development, the log from each\nprocess of the Procfile is logged in the terminal window.", "content_type": "prose", "has_code": false, "token_count": 36}
{"chunk_id": "11_testing_debugging__debugging__003", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "Server", "content": "## Server\n\nWhen you run the `bench start` command during development, the log from each\nprocess of the Procfile is logged in the terminal window.\n\n```python\n\u25b6 bench start\n14:55:17 system | redis_cache.1 started (pid=4085)\n14:55:17 system | redis_socketio.1 started (pid=4086)\n14:55:17 system | redis_queue.1 started (pid=4088)\n14:55:17 system | web.1 started (pid=4089)\n14:55:17 system | socketio.1 started (pid=4090)\n14:55:17 system | watch.1 started (pid=4094)\n14:55:17 system | worker_short.1 started (pid=4096)\n14:55:17 system | schedule.1 started (pid=4095)\n14:55:17 redis_queue.1 | 4088:C 22 May 14:55:17.257 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n14:55:17 redis_queue.1 | 4088:C 22 May 14:55:17.264 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=4088, just started\n14:55:17 redis_queue.1 | 4088:C 22 May 14:55:17.264 # Configuration loaded\n14:55:17 redis_queue.1 | 4088:M 22 May 14:55:17.265 * Increased maximum number of open files to 10032 (it was originally set to 4864).\n14:55:17 redis_cache.1 | 4085:C 22 May 14:55:17.262 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n14:55:17 redis_cache.1 | 4085:C 22 May 14:55:17.268 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=4085, just started\n14:55:17 redis_cache.1 | 4085:C 22 May 14:55:17.268 # Configuration loaded\n14:55:17 redis_cache.1 | 4085:M 22 May 14:55:17.269 * Increased maximum number of open files to 10032 (it was originally set to 4864).\n14:55:17 redis_socketio.1 | 4086:C 22 May 14:55:17.262 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n14:55:17 redis_socketio.1 | 4086:C 22 May 14:55:17.270 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=4086, just started\n14:55:17 redis_socketio.1 | 4086:C 22 May 14:55:17.270 # Configuration loaded\n14:55:17 redis_socketio.1 | 4086:M 22 May 14:55:17.272 * Increased maximum number of open files to 10032 (it was originally set to 4864).\n14:55:17 redis_queue.1 | 4088:M 22 May 14:55:17.285 * Running mode=standalone, port=11002.\n14:55:17 redis_queue.1 | 4088:M 22 May 14:55:17.285 # Server initialized\n14:55:17 redis_queue.1 | 4088:M 22 May 14:55:17.286 * Ready to accept connections\n14:55:17 redis_cache.1 | 4085:M 22 May 14:55:17.287 * Running mode=standalone, port=13002.\n14:55:17 redis_cache.1 | 4085:M 22 May 14:55:17.292 # Server initialized\n14:55:17 redis_cache.1 | 4085:M 22 May 14:55:17.292 * Ready to accept connections\n14:55:17 redis_socketio.1 | 4086:M 22 May 14:55:17.294 * Running mode=standalone, port=12002.\n14:55:17 redis_socketio.1 | 4086:M 22 May 14:55:17.294 # Server initialized\n14:55:17 redis_socketio.1 | 4086:M 22 May 14:55:17.295 * Ready to accept connections\n14:55:17 system | worker_long.1 started (pid=4098)\n14:55:17 system | worker_default.1 started (pid=4100)\n14:55:18 socketio.1 | listening on *: 9002\n14:55:20 socketio.1 | { Error: connect ECONNREFUSED 0.0.0.0:8002\n14:55:20 socketio.1 | at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1191:14)\n14:55:20 socketio.1 | errno: 'ECONNREFUSED',\n14:55:20 socketio.1 | code: 'ECONNREFUSED',\n14:55:20 socketio.1 | syscall: 'connect',\n14:55:20 socketio.1 | address: '0.0.0.0',\n14:55:20 socketio.1 | port: 8002,\n14:55:20 socketio.1 | response: undefined }\n14:55:24 web.1 | * Running on http://0.0.0.0:8002/ (Press CTRL+C to quit)\n14:55:24 web.1 | * Restarting with fsevents reloader\n14:55:24 watch.1 | yarn run v1.10.1\n14:55:24 watch.1 | $ node rollup/watch.js\n14:55:25 web.1 | * Debugger is active!\n14:55:25 web.1 | * Debugger PIN: 321-355-865\n14:55:26 watch.1 |\n14:55:26 watch.1 | Rollup Watcher Started\n14:55:26 watch.1 |\n14:55:26 watch.1 | Watching...\n14:55:26 watch.1 | Rebuilding frappe-web.css\n14:55:27 watch.1 | Rebuilding frappe-web-b4.css\n14:55:27 watch.1 | Rebuilding chat.js\n14:55:28 web.1 |\n14:55:28 web.1 | test print\n```", "content_type": "mixed", "has_code": true, "token_count": 948}
{"chunk_id": "11_testing_debugging__debugging__004", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "Server", "content": "## Server\n\nWhen you write any print statements in your python code, it will show up in the\n`web:` process log if it is a request/response, or in one of `worker_` processes\nif the code runs in a background job.\n\n> If you are a VSCode user, you can debug right in your editor by setting\n> breakpoints in your code. Follow these\n> [steps](https://github.com/frappe/erpnext/wiki/VSCode-Debugging-for-Frappe-Python)\n> to set it up.", "content_type": "prose", "has_code": false, "token_count": 106}
{"chunk_id": "11_testing_debugging__debugging__005", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "Logging", "content": "## Logging\n\nIn case you're running production, you'd need logs all the more to keep track of as much information about your Frappe environment.\n\nOut of the box, logs are stored under the `./logs` folder in your bench. From Frappe Version 13, logs are available at site level too, under `./sites/{site}/logs`.\n\nThese site logs are created by the Frappe Application, while many of the bench level log files are generated by the processes that support your Frappe environment. Checkout `Procfile` or `supervisor.conf` in your bench for more information.\n\n> Learn more about Frappe Logs [here](/framework/v14/user/en/logging) and the Frappe Logging API from [here](/framework/v14/user/en/api/logging).\n\n### Console\n\nTo play with Python API, bench provides an iPython shell. After you run the\nfollowing command, it will import frappe, initialize it and also connect to\ndatabase.\n\n```python\n\u25b6 bench --site [sitename] console\n\nIn [1]: frappe.get_doc('Task', 'TASK00004')\nOut[1]: <erpnext.projects.doctype.task.task.task at=\"\" 0x10825d710=\"\">\n```\n\n### Client\n\nClient side debugging is as simple as adding a `debugger` statement in your JS\nfile. You must open your DevTools in your browser for it to pause on the statement.\n\n```python\nfrappe.db.get_value('Task', 'TASK00004', 'status')\n .then(values => {\n debugger\n console.log(values);\n })\n```\n\n### Console\n\nTo play with Client API, you can open your browser's console and use the\nglobally available `frappe` object to explore and run methods and access\nproperties.\n\n![Browser Console](/files/client-side-debugging.png)\n*Browser Console*\n\n> Learn more about the Client API [here](/framework/v14/user/en/api#javascript)\n> </erpnext.projects.doctype.task.task.task>", "content_type": "mixed", "has_code": true, "token_count": 426}
{"chunk_id": "11_testing_debugging__debugging__006", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "Debugging in VS Code / Debug Adapter Protocol", "content": "## Debugging in VS Code / Debug Adapter Protocol\n\n![vsc debugging](/files/vsc_debuggin.png)\n\nChecklist for proper functioning.\n\n* Update `Procfile`\n* Get Visual Studio Code (duh!)\n* Install [Python Extension for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-python.python)\n* Update `launch.json`\n* Start Debugging\n\nCaveats:\n\n1. Disables Auto Reload Feature (However You can achieve the same results by manual reload (\u2318\u21e7F5))\n2. Disables Werkzeug Multithreading\n\n**1. Update `Procfile`**\n\n*Caution: This modifies the behaviour of `bench start`*\n\nComment out a line (prepend # to it) from the `Procfile` (located in the bench directory) that looks like this.\n\n```python\nweb: bench serve --port 8000\n```\n\nWe will run this process from VS code instead of running it with `bench start`.\n\n**2. Update `launch.json`**\nAdd a configuration to your `launch.json` in VS Code that should look something like this (This more or less does exactly what the removed line from Procfile does).\n\n```python\n{\n \"name\": \"Bench\",\n \"type\": \"python\",\n \"request\": \"launch\",\n \"program\": \"${workspaceFolder}/frappe/frappe/utils/bench_helper.py\",\n \"args\": [\n \"frappe\", \"serve\", \"--port\", \"8000\", \"--noreload\", \"--nothreading\"\n ],\n \"pythonPath\": \"${workspaceFolder}/../env/bin/python\",\n \"cwd\": \"${workspaceFolder}/../sites\",\n \"env\": {\n \"DEV_SERVER\": \"1\"\n }\n}\n```\n\nPaths mentioned in given configuration assumes that you have `apps` directory as your workspace directory (The directory you open `code` with). `workspaceFolder` is a vs code variable that points to (if it's not obvious from its name) workspace directory.\n\nYou are not forced to use `apps` as your workspace directory, however do remember to change `workspaceFolder`, `pythonPath` and `cwd` accordingly.\n\n**3. Execute `bench start`**\n\nThis should be kept running as usual.\n\n**4. Start debugging**\n\nVS Code -> Debug Panel (\u2318\u21e7D) -> Start Debugging or With a keyboard shortcut(\u2318\u21e7F5).", "content_type": "mixed", "has_code": true, "token_count": 482}
{"chunk_id": "11_testing_debugging__debugging__007", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/debugging", "title": "Debugging", "section_heading": "Explanation", "content": "## Explanation\n\n**1. `program` and `args`**\n\n```python\n\"program\": \"${workspaceFolder}/frappe/frappe/utils/bench_helper.py\",\n\"args\": [\"frappe\", \"serve\", \"--port\", \"8000\", \"--noreload\", \"--nothreading\"],\n```\n\nDoes exact same thing as `bench serve --port 8000 --noreload --nothreading` which is same as\n\n```python\ncd sites\n../env/bin/python ../apps/frappe/frappe/utils/bench_helper.py frappe serve --port 8000 --noreload --nothreading\n```\n\n`--noreload` diasbles werkezeug's autoreload fetaure and `--nothreading` disables multithreading.\n\n**2. `cwd`**\n\n```python\n\"cwd\": \"${workspaceFolder}/../sites\",\n```\n\nAbove command must be executed from `sites` directory.\n\n**3. `env`**\n\n```python\n\"env\": {\n \"DEV_SERVER\": \"1\"\n}\n```\n\n`bench start` creates an environment variable `DEV_SERVER` and set it to `1`. Socket.io doesn't work correctly without this (long story).\n\nRunning only `bench serve` doesn't set this variable so you need to explicitly set it.\n\n**Note:**\n\nCurrently, frappe runs with `use_reloader=True` and `threaded=True`, VS Code Debugger for some reason doesn't play well with these features, [Django and Flask](https://code.visualstudio.com/docs/python/debugging#_debugging-specific-app-types) also have this problem.", "content_type": "mixed", "has_code": true, "token_count": 305}
{"chunk_id": "11_testing_debugging__profiling__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/profiling", "title": "Profiling", "section_heading": "Recorder - SQL profiler", "content": "## Recorder - SQL profiler\n\nFrappe Recorder is a profiling tool built into the Frappe framework designed to capture all requests, SQL queries executed along with stack traces.\n\nExample use case: You've noticed that a certain doctype is taking too much time to save and you believe that SQL queries might be a bottleneck. In such a case starting recorder and then submitting your document will give you complete capture of all the queries that took place.\n\n1. Open Recorder from Awesomebar and click on \"Start recording\".\n2. Perform the actions you want to profile (preferably in another tab.)\n3. Once you've captured enough information, go to the recorder again and stop recording.\n\nYou will now see a list of all the requests that were made. You can sort them by various columns to identify problematic requests.\n\n![Frappe recorder list view](/files/recorder-list-view.png)\n\nClick on a row to open the request for extra information. Following information is available in capture:\n\n1. path - requested path e.g. `/app`\n2. cmd - dotted path to the method\n3. time - time at which request was created\n4. duration - duration for completing the request (see implementation note below)\n5. number of queries - Number of SQL queries executed for fulfilling the request.\n6. Time in queries - Time taken in SQL queries.\n7. Request headers - HTTP headers received with the request.\n8. Form Dict - form data received with the request.\n9. SQL queries - table of all SQL queries that ran.\n\n![Frappe recorder request view](/files/recorder-request-view.png)\n\nSQL Queries table can be sorted and grouped for duplicates to find the relevant queries. To know more about a particular query click on row to expand additional information. This includes the duration of the query, stack trace and SQL's `EXPLAIN` output for that query.\n\n> Implementation note: Recorder adds sizable overhead for capturing the details, hence overall duration is not representative of real-world performance. Query time however is very close to real-world performance.\n\n### Exporting Frappe Recorder captures\n\nYou can export recorder captures and import them on another site for further analysis.\n\n1. Go to recorder page. Once you've recorded click on Menu (three dots) > Export Data.\n2. This will download a JSON file containing captured data. To view this on another site drag and drop the JSON file on the recorder page.\n\n### Profiling functions using bench\n\nBench's `execute` command runs a dotted path to method and it also supports\nprofiling.\n\n```python\n\u25b6 bench --site [sitename] --profile execute erpnext.projects.doctype.task.task.set_tasks_as_overdue\n```\n\nYou should be able to run most commands you can run via console with `execute` now, including *db* methods.\n\n```python\n\u25b6 bench --site [sitename] execute frappe.db.get_database_size\n6784\n```", "content_type": "mixed", "has_code": true, "token_count": 703}
{"chunk_id": "11_testing_debugging__profiling__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/profiling", "title": "Profiling", "section_heading": "Frappe Monitor", "content": "## Frappe Monitor\n\nMonitor logs request and job metadata. To enable this feature set `\"monitor\": 1` in your site config.\n\nCollected data is buffered in redis cache and periodically moved to `monitor.json.log` file in `logs` directory with a scheduled job `frappe.monitor.flush`.\n\n```python\n{\n \"duration\": 807142,\n \"request\": {\n \"ip\": \"127.0.0.1\",\n \"method\": \"GET\",\n \"path\": \"/api/method/frappe.realtime.get_user_info\",\n \"response_length\": 9687,\n \"status_code\": 500\n },\n \"site\": \"frappe.local\",\n \"timestamp\": \"2020-03-05 09:37:17.397884\",\n \"transaction_type\": \"request\",\n \"uuid\": \"83be6a4c-27a1-497a-9ce6-c815bca4e420\"\n}\n```\n\n```python\n{\n \"duration\": 1364,\n \"job\": {\n \"method\": \"frappe.ping\",\n \"scheduled\": false,\n \"wait\": 90204\n },\n \"site\": \"frappe.local\",\n \"timestamp\": \"2020-03-05 09:37:40.124682\",\n \"transaction_type\": \"job\",\n \"uuid\": \"8225ab76-8bee-462c-b9fc-a556406b1ee7\"\n}\n```\n\n### Background Jobs monitoring\n\nFrappe uses RQ (Redis Queue) for asynchronously executing long tasks in background. You can monitor RQ using these inbuilt virtual doctypes:\n\n### 1. RQ Worker - Monitoring a background worker\n\nRQ worker doctype shows all background workers consuming the background jobs queue on your site. It also contrains basic statistics about the worker like name, timing, successful and failed jobs count and currently status.\n\n### 2. RQ Job - Monitoring and controlling background jobs.\n\nRQ Job is a virtual doctype which provides information about all background jobs. You can filter jobs by queue and status.\n\n![rq job list](/private/files/rq_job_list.png)\n\nForm view of RQ job shows all information about the job.\n\n![rq job](/private/files/rq_job.png)", "content_type": "mixed", "has_code": true, "token_count": 415}
{"chunk_id": "11_testing_debugging__logging__001", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/logging", "title": "Logging", "section_heading": "Desk Logs", "content": "## Desk Logs\n\nLogging events can significantly improve the debugging experience. Frappe's\ndevelopment and production environments come with logging capabilities out of\nthe box.\n\nThere's two main categories of logs based on accessibility. Desk Logs, which are\nstored in your site database and can be accessed and queried as Documents and\nthe Server Logs, that are stored in files managed by a Log Rotation system.\n\n### Desk Logs\n\nLogs that can be accessed via the Desk UI \\_(generally searched for, from the\n[Awesomebar](/framework/v14/user/en/desk#awesomebar))\\_. These track the operational\nevents generally; but you can utilize their APIs to track about anything from\nyour Frappe apps.\n\nSome of the logs in the `Core` module are:\n\n* [Access\n  Log](https://docs.erpnext.com/docs/user/manual/en/using-erpnext/access-log)\n* [Activity Log](#activity-log)\n* [Error\n  Log](https://frappe.io/blog/development/better-error-logging-with-frappe)\n* [Scheduled Job Log](#scheduled-job-log)\n\nYou can find more information about them from the embedded links. The best way\nto find out more about each of them is checking them out directly on your site.", "content_type": "prose", "has_code": false, "token_count": 284}
{"chunk_id": "11_testing_debugging__logging__002", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/logging", "title": "Logging", "section_heading": "Server Logs", "content": "## Server Logs\n\nServer Logs generally consist of lower level, transactional data as compared to\nthose accessible from Desk. From Version 13, logs are available at site level\ntoo. These site logs are created by the Frappe Application, while many of the\nbench level log files are generated by the processes that support your Frappe\nenvironment. From your bench folder, you may find logs under:\n\n* `./logs`\n* `./sites/{site}/logs`\n\nAt the time of writing this, only `frappe.web.log` and `scheduler.log` are\nlogged at site and bench-level. At bench level, some of the most useful files\ncould be:\n\n* `bench.log`\n* `scheduler.log`\n* `worker.log`\n\nTracking the bench commands executed, status of the jobs run by your Scheduler\nor [Background\nJobs](/framework/v14/user/en/guides/app-development/running-background-jobs) can be found\nin these logs.\n\n> To enable Frappe Web Logging on your site, update the site config with\n> `enable_frappe_logger`: `true`", "content_type": "prose", "has_code": false, "token_count": 236}
{"chunk_id": "11_testing_debugging__logging__003", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/logging", "title": "Logging", "section_heading": "Error Snapshots", "content": "## Error Snapshots\n\nAlong with these, Frappe maintains error snapshots for your sites for HTTP\nresponse codes from 500 and above. This is done in order to provide more context\nfor failures in case of server errors. Consider, a desk action failing with HTTP\nstatus code 500, this would add a corresponding log in the\n`./sites/{site}/frappe.log` file as follows:\n\n```python\n2021-05-06 14:08:12,177 ERROR frappe New Exception collected with snapshot id: 2021-05-06 14:08:11.940809-127.0.0.1-bde\nSite: frappeframework.com\nForm Dict: {'docs': '{\"name\":\"assets.frappeframework.com\",\"owner\":\"Administrator\",\"creation\":\"2020-04-04 14:58:18.771247\",\"modified\":\"2021-02-08 09:40:56.820300\",\"modified_by\":\"gavin@frappe.io\",\"idx\":0,\"docstatus\":0,\"status\":\"Active\",\"hostname\":\"assets\",\"domain\":\"frappeframework.com\",\"cluster\":\"Default\",\"provider\":\"Generic\",\"is_server_setup\":1,\"ip\":\"192.168.29.100\",\"private_ip\":\"10.120.120.120\",\"agent_password\":\"*****\",\"is_primary\":1,\"doctype\":\"Server\",\"__last_sync_on\":\"2021-05-06T08:38:08.931Z\"}', 'method': 'ping_agent', 'cmd': 'run_doc_method'}\n```\n\nThe first line of the log mentions the snapshot ID of the error, which in this\ncase was `2021-05-06 14:08:11.940809-127.0.0.1-bde`. A corresponding file\nidentified with the snapshot ID should be under\n`./sites/frappeframework.com/error-snapshots`, with the name `2021-05-06 14:08:11.940809-127.0.0.1-bde.json`. Contents of the file may be:", "content_type": "mixed", "has_code": true, "token_count": 353}
{"chunk_id": "11_testing_debugging__logging__004", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/logging", "title": "Logging", "section_heading": "Error Snapshots", "content": "## Error Snapshots\n\nThe first line of the log mentions the snapshot ID of the error, which in this\ncase was `2021-05-06 14:08:11.940809-127.0.0.1-bde`. A corresponding file\nidentified with the snapshot ID should be under\n`./sites/frappeframework.com/error-snapshots`, with the name `2021-05-06 14:08:11.940809-127.0.0.1-bde.json`. Contents of the file may be:\n\n```python\n {\n \"etype\": \"UnboundLocalError\",\n \"evalue\": \"UnboundLocalError(\"local variable 'headers' referenced before assignment\")\",\n \"exception\": {\n \"args\": [...],\n \"with_traceback\": [...]\n },\n \"frames\": [\n {\n \"call\": \"(request=<request 'https:=\"\" frappeframework.com=\"\" api=\"\" method=\"\" run_doc_method'=\"\" [post]=\"\">)\",\n \"dump\": {\n \"frappe. api\": \"<module 'frappe.api'=\"\" from=\"\" '=\"\" home=\"\" frappe=\"\" frappe-bench=\"\" apps=\"\" api.py'=\"\">\",\n \"frappe.api. handle\": \"<function handle=\"\">\",\n \"global frappe\": \"<module 'frappe'=\"\" from=\"\" '=\"\" home=\"\" frappe=\"\" frappe-bench=\"\" apps=\"\" __init__.py'=\"\">\",\n \"response\": \"None\"\n },\n \"file\": \"/home/frappe/frappe-bench/apps/frappe/frappe/app.py\",\n \"func\": \"application\",\n \"lines\": {\n \"66\": \"\",\n \"67\": \"elif request.path.startswith(\"/api/\"):\",\n \"68\": \"response = frappe.api.handle()\",\n \"69\": \"\",\n \"70\": \"elif request.path.startswith('/backups'):\"\n },\n \"lnum\": 68\n },\n ...\n ],\n \"locals\": {\n \"data\": \"None\",\n \"files\": \"None\",\n \"method\": \"GET\",\n \"path\": \"ping\",\n \"self\": \"<orchestrator.agent.agent object=\"\">\",\n \"url\": \"https://assets.frappeframework.com:443/agent/ping\"\n },\n \"pyver\": \"Python 3.8.2: /home/frappe/frappe-bench/env/bin/python (prefix: /home/frappe/frappe-bench/env)\",\n \"timestamp\": \"2021-05-06 14:08:11.940971\",\n \"traceback\": \"Traceback (most recent call last):\n File \"/home/frappe/frappe-bench/env/lib/python3.8/site-packages/cryptography/fernet.py\", line 119, in _verify_signature\n h.verify(data[-32:])\n File \"/home/frappe/frappe-bench/env/lib/python3.8/site-packages/cryptography/hazmat/primitives/hmac.py\", line 74, in verify\n ctx.verify(signature)\n File \"/home/frappe/frappe-bench/env/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/hmac.py\", line 75, in verify\n raise InvalidSignature(\"Signature did not match digest.\")\ncryptography.exceptions.InvalidSignature: Signature did not match digest.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \"/home/frappe/frappe-bench/apps/frappe/frappe/app.py\", line 68, in application\n response = frappe.api.handle()\n File \"/home/frappe/frappe-bench/apps/frappe/frappe/api.py\", line 54, in handle\n return frappe.handler.handle()\n File \"/home/frappe/frappe-bench/apps/orchestrator/orchestrator/agent.py\", line 474, in request\n headers=headers,\nUnboundLocalError: local variable 'headers' referenced before assignment\n\"\n }\n```\n\nThese snapshots are synced periodically with the site's database and are\navailable via the desk with records added under the DocType **Error Snapshot**. They\nare maintained for a month from creation before each record is deleted.\n\n> Error snapshots are tracked by default. To disable this for your site, update\n> the site config with `disable_error_snapshot`: `true`", "content_type": "mixed", "has_code": true, "token_count": 782}
{"chunk_id": "11_testing_debugging__logging__005", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/logging", "title": "Logging", "section_heading": "Processes", "content": "## Processes\n\nServer Logs may be generated by the [bench CLI](/framework/v14/user/en/bench),\nyour process manager or the Frappe application directly. Your process managers\ntake care of getting all the moving parts up and running for your Frappe\nenvironment as well as directing output and error streams to your log files.\n\nApart from the *\"always running\"* default logging, you can also use\n[Monitor](/framework/v14/user/en/debugging#monitoring) to log more information about all\nthe requests to your site.\n\n### Maintainence\n\nThe log files generated by your process manager may get pretty large over time\nif you aren't paying attention. To know which files you have to track for this,\ncheckout the `supervisor.conf` or `Procfile` on your bench, depending on whether\nyou're running a production or development instance respectively.", "content_type": "prose", "has_code": false, "token_count": 207}
{"chunk_id": "11_testing_debugging__logging__006", "module": "11_testing_debugging", "source_url": "https://docs.frappe.io/framework/v15/user/en/logging", "title": "Logging", "section_heading": "Auto cleanup of old logs", "content": "## Auto cleanup of old logs\n\nMost logging doctypes in Frappe support configurable retention period with sane defaults.\n\n\"Log Settings\" doctype lets you configure retention period for default logging doctypes.\n\n![Log Settings](/files/log_settings.png)\n\nYou can also register your custom logging doctype with log settings by adding a single static method to your doctype controller like this. Custom logging doctypes which implement this method will automatically show up in Log Settings.\n\n```python\nclass CustomLoggingDoctype(Document):\n @staticmethod\n def clear_old_logs(days=180):\n from frappe.query_builder import Interval\n from frappe.query_builder.functions import Now\n\n table = frappe.qb.DocType(\"Custom Logging Doctype\")\n frappe.db.delete(table, filters=(table.modified < (Now() - Interval(days=days))))\n```\n\n### More\n\nIn a production environment, you'd likely want to log more information for your\nFrappe Applications or the processes that make up your Frappe Environment.\nHere's some resources you could go over to find out more.\n\nFrappe Application\n\n* [Frappe Logging API](/framework/v14/user/en/api/logging)\n\nServer Monitoring\n\n* [MySQL](https://dev.mysql.com/doc/refman/5.7/en/server-logs.html)\n* [PostgreSQL](https://www.postgresql.org/docs/current/runtime-config-logging.html)\n* [NGINX](https://docs.nginx.com/nginx/admin-guide/monitoring/logging/)\n  </orchestrator.agent.agent>", "content_type": "mixed", "has_code": true, "token_count": 347}
